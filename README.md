
# ðŸ§  Neural Network from Scratch â€” Titanic Dataset

## ðŸ“˜ Project Overview
This project implements a simple feedforward **neural network (3-2-2-1 architecture)** entirely from scratch using **NumPy**.  
No `sklearn`, no `keras`, no pre-built layers â€” every forward and backward computation is manually defined.

The goal is to strengthen understanding of **how neural networks actually work under the hood** â€” from forward propagation to gradient updates â€” without relying on any deep learning frameworks.

---

## âš™ï¸ Training Configuration
| Parameter | Value |
|------------|--------|
| Learning Rate | 0.01 |
| Epochs | 500 |
| Loss Function | Binary Cross-Entropy |
| Optimizer | Manual Gradient Descent |

---

## ðŸ“Š Results
| Metric | Value |
|---------|--------|
| Training Accuracy | 79.21 |
| Validation Accuracy | 77.65 |

> Results may vary due to random initialization.

---

## ðŸ’¡ Key Learnings
- Implementing backpropagation manually deepened understanding of gradient flow.  
- Debugging vanishing/exploding gradients built intuition for weight initialization.  
- Reinforced why frameworks like TensorFlow and PyTorch abstract these details.

---

## ðŸ”® Next Steps
- Implement momentum or Adam optimizer manually  
- Compare manual network vs. sklearnâ€™s `MLPClassifier`  
- Experiment with different activation functions or architectures  

---

## ðŸ§° How to Run
- git clone https://github.com/srujanx/ANN_from_scratch_titanic.git
- cd ANN_from_scratch_titanic
- pip install numpy pandas matplotlib
- jupyter notebook ANN_Titanic-2.ipynb

---

## ðŸªª License
MIT License â€” free to use, modify, and share.

## ðŸ‘¤ Author
Srujan
Bachelorâ€™s in Artificial Intelligence, Durham College (Canada)
- LinkedIn : www.linkedin.com/in/srujan77
